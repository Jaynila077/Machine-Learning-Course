{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac99fb5-8595-4e1f-969d-6a07f4ca9800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4941c2-2aa1-4618-b8da-45b8f04e38e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# tf.constant and Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db37c73b-0391-4431-a4c3-2fa43d845285",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Const'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Creates a constant tensor from a tensor-like object.\n",
       "\n",
       "Note: All eager `tf.Tensor` values are immutable (in contrast to\n",
       "`tf.Variable`). There is nothing especially _constant_ about the value\n",
       "returned from `tf.constant`. This function is not fundamentally different from\n",
       "`tf.convert_to_tensor`. The name `tf.constant` comes from the `value` being\n",
       "embedded in a `Const` node in the `tf.Graph`. `tf.constant` is useful\n",
       "for asserting that the value can be embedded that way.\n",
       "\n",
       "If the argument `dtype` is not specified, then the type is inferred from\n",
       "the type of `value`.\n",
       "\n",
       ">>> # Constant 1-D Tensor from a python list.\n",
       ">>> tf.constant([1, 2, 3, 4, 5, 6])\n",
       "<tf.Tensor: shape=(6,), dtype=int32,\n",
       "    numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
       ">>> # Or a numpy array\n",
       ">>> a = np.array([[1, 2, 3], [4, 5, 6]])\n",
       ">>> tf.constant(a)\n",
       "<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[1, 2, 3],\n",
       "         [4, 5, 6]])>\n",
       "\n",
       "If `dtype` is specified, the resulting tensor values are cast to the requested\n",
       "`dtype`.\n",
       "\n",
       ">>> tf.constant([1, 2, 3, 4, 5, 6], dtype=tf.float64)\n",
       "<tf.Tensor: shape=(6,), dtype=float64,\n",
       "    numpy=array([1., 2., 3., 4., 5., 6.])>\n",
       "\n",
       "If `shape` is set, the `value` is reshaped to match. Scalars are expanded to\n",
       "fill the `shape`:\n",
       "\n",
       ">>> tf.constant(0, shape=(2, 3))\n",
       "  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[0, 0, 0],\n",
       "         [0, 0, 0]], dtype=int32)>\n",
       ">>> tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[1, 2, 3],\n",
       "         [4, 5, 6]], dtype=int32)>\n",
       "\n",
       "`tf.constant` has no effect if an eager Tensor is passed as the `value`, it\n",
       "even transmits gradients:\n",
       "\n",
       ">>> v = tf.Variable([0.0])\n",
       ">>> with tf.GradientTape() as g:\n",
       "...     loss = tf.constant(v + v)\n",
       ">>> g.gradient(loss, v).numpy()\n",
       "array([2.], dtype=float32)\n",
       "\n",
       "But, since `tf.constant` embeds the value in the `tf.Graph` this fails for\n",
       "symbolic tensors:\n",
       "\n",
       ">>> with tf.compat.v1.Graph().as_default():\n",
       "...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
       "...   t = tf.constant(i)\n",
       "Traceback (most recent call last):\n",
       "...\n",
       "TypeError: ...\n",
       "\n",
       "`tf.constant` will create tensors on the current device. Inputs which are\n",
       "already tensors maintain their placements unchanged.\n",
       "\n",
       "Related Ops:\n",
       "\n",
       "* `tf.convert_to_tensor` is similar but:\n",
       "  * It has no `shape` argument.\n",
       "  * Symbolic tensors are allowed to pass through.\n",
       "\n",
       "  >>> with tf.compat.v1.Graph().as_default():\n",
       "  ...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
       "  ...   t = tf.convert_to_tensor(i)\n",
       "\n",
       "* `tf.fill`: differs in a few ways:\n",
       "  *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
       "      Tensors like `tf.fill`.\n",
       "  *   `tf.fill` creates an Op in the graph that is expanded at runtime, so it\n",
       "      can efficiently represent large tensors.\n",
       "  *   Since `tf.fill` does not embed the value, it can produce dynamically\n",
       "      sized outputs.\n",
       "\n",
       "Args:\n",
       "  value: A constant value (or list) of output type `dtype`.\n",
       "  dtype: The type of the elements of the resulting tensor.\n",
       "  shape: Optional dimensions of resulting tensor.\n",
       "  name: Optional name for the tensor.\n",
       "\n",
       "Returns:\n",
       "  A Constant Tensor.\n",
       "\n",
       "Raises:\n",
       "  TypeError: if shape is incorrectly specified or unsupported.\n",
       "  ValueError: if called on a symbolic tensor.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.constant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "041cae7d-fe31-43ca-88cd-4b439d53c735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = tf.constant(10)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5232ff2-0a1b-4416-bcaa-0554142d1242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  4], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([10,4])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d142c3c-b3a5-4420-afb0-8b862c7d3e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  4],\n",
       "       [11,  3]], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[10,4],\n",
    "                     [11,3]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "893b876c-1f21-4809-89a4-cce95074b93c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[10,  4],\n",
       "        [11,  3]],\n",
       "\n",
       "       [[11,  2],\n",
       "        [11,  4]]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[[10,4],[11,3]],\n",
    "                      [[11,2],[11,4]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b09b81e1-08e6-4011-8e38-7141065711a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1cd8093-cab3-4fe1-99be-2799220a60a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a7ee6a2-c2bd-492a-b6f0-12e53da0e145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c8a3a09-67cc-4e5b-b038-f67bbb153978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d5e83-b3cb-4e0a-b9e2-997d8109763e",
   "metadata": {},
   "source": [
    "# tf.variables and Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24b0c0e-c681-4e36-9789-d95fdc7d0f97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "See the [variable guide](https://tensorflow.org/guide/variable).\n",
       "\n",
       "A variable maintains shared, persistent state manipulated by a program.\n",
       "\n",
       "The `Variable()` constructor requires an initial value for the variable, which\n",
       "can be a `Tensor` of any type and shape. This initial value defines the type\n",
       "and shape of the variable. After construction, the type and shape of the\n",
       "variable are fixed. The value can be changed using one of the assign methods.\n",
       "\n",
       ">>> v = tf.Variable(1.)\n",
       ">>> v.assign(2.)\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
       ">>> v.assign_add(0.5)\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.5>\n",
       "\n",
       "The `shape` argument to `Variable`'s constructor allows you to construct a\n",
       "variable with a less defined shape than its `initial_value`:\n",
       "\n",
       ">>> v = tf.Variable(1., shape=tf.TensorShape(None))\n",
       ">>> v.assign([[1.]])\n",
       "<tf.Variable ... shape=<unknown> dtype=float32, numpy=array([[1.]], ...)>\n",
       "\n",
       "Just like any `Tensor`, variables created with `Variable()` can be used as\n",
       "inputs to operations. Additionally, all the operators overloaded for the\n",
       "`Tensor` class are carried over to variables.\n",
       "\n",
       ">>> w = tf.Variable([[1.], [2.]])\n",
       ">>> x = tf.constant([[3., 4.]])\n",
       ">>> tf.matmul(w, x)\n",
       "<tf.Tensor:... shape=(2, 2), ... numpy=\n",
       "  array([[3., 4.],\n",
       "         [6., 8.]], dtype=float32)>\n",
       ">>> tf.sigmoid(w + x)\n",
       "<tf.Tensor:... shape=(2, 2), ...>\n",
       "\n",
       "When building a machine learning model it is often convenient to distinguish\n",
       "between variables holding trainable model parameters and other variables such\n",
       "as a `step` variable used to count training steps. To make this easier, the\n",
       "variable constructor supports a `trainable=<bool>`\n",
       "parameter. `tf.GradientTape` watches trainable variables by default:\n",
       "\n",
       ">>> with tf.GradientTape(persistent=True) as tape:\n",
       "...   trainable = tf.Variable(1.)\n",
       "...   non_trainable = tf.Variable(2., trainable=False)\n",
       "...   x1 = trainable * 2.\n",
       "...   x2 = non_trainable * 3.\n",
       ">>> tape.gradient(x1, trainable)\n",
       "<tf.Tensor:... shape=(), dtype=float32, numpy=2.0>\n",
       ">>> assert tape.gradient(x2, non_trainable) is None  # Unwatched\n",
       "\n",
       "Variables are automatically tracked when assigned to attributes of types\n",
       "inheriting from `tf.Module`.\n",
       "\n",
       ">>> m = tf.Module()\n",
       ">>> m.v = tf.Variable([1.])\n",
       ">>> m.trainable_variables\n",
       "(<tf.Variable ... shape=(1,) ... numpy=array([1.], dtype=float32)>,)\n",
       "\n",
       "This tracking then allows saving variable values to\n",
       "[training checkpoints](https://www.tensorflow.org/guide/checkpoint), or to\n",
       "[SavedModels](https://www.tensorflow.org/guide/saved_model) which include\n",
       "serialized TensorFlow graphs.\n",
       "\n",
       "Variables are often captured and manipulated by `tf.function`s. This works the\n",
       "same way the un-decorated function would have:\n",
       "\n",
       ">>> v = tf.Variable(0.)\n",
       ">>> read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
       ">>> read_and_decrement()\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.1>\n",
       ">>> read_and_decrement()\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.2>\n",
       "\n",
       "Variables created inside a `tf.function` must be owned outside the function\n",
       "and be created only once:\n",
       "\n",
       ">>> class M(tf.Module):\n",
       "...   @tf.function\n",
       "...   def __call__(self, x):\n",
       "...     if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
       "...       self.v = tf.Variable(x)\n",
       "...     return self.v * x\n",
       ">>> m = M()\n",
       ">>> m(2.)\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n",
       ">>> m(3.)\n",
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
       ">>> m.v\n",
       "<tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
       "\n",
       "See the `tf.function` documentation for details.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Creates a new variable with value `initial_value`. (deprecated arguments)\n",
       "\n",
       "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(caching_device)`. They will be removed in a future version.\n",
       "Instructions for updating:\n",
       "A variable's value can be manually cached by calling tf.Variable.read_value() under a tf.device scope. The caching_device argument does not work properly.\n",
       "\n",
       "Args:\n",
       "  initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
       "    which is the initial value for the Variable. The initial value must have\n",
       "    a shape specified unless `validate_shape` is set to False. Can also be a\n",
       "    callable with no argument that returns the initial value when called. In\n",
       "    that case, `dtype` must be specified. (Note that initializer functions\n",
       "    from init_ops.py must first be bound to a shape before being used here.)\n",
       "  trainable: If `True`, GradientTapes automatically watch uses of this\n",
       "    variable. Defaults to `True`, unless `synchronization` is set to\n",
       "    `ON_READ`, in which case it defaults to `False`.\n",
       "  validate_shape: If `False`, allows the variable to be initialized with a\n",
       "    value of unknown shape. If `True`, the default, the shape of\n",
       "    `initial_value` must be known.\n",
       "  caching_device: Note: This argument is only valid when using a v1-style\n",
       "    `Session`. Optional device string describing where the Variable should\n",
       "    be cached for reading. Defaults to the Variable's device. If not `None`,\n",
       "    caches on another device. Typical use is to cache on the device where\n",
       "    the Ops using the Variable reside, to deduplicate copying through\n",
       "    `Switch` and other conditional statements.\n",
       "  name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
       "    uniquified automatically.\n",
       "  variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
       "    Variable object with its contents, referencing the variable's nodes in\n",
       "    the graph, which must already exist. The graph is not changed.\n",
       "    `variable_def` and the other arguments are mutually exclusive.\n",
       "  dtype: If set, initial_value will be converted to the given type. If\n",
       "    `None`, either the datatype will be kept (if `initial_value` is a\n",
       "    Tensor), or `convert_to_tensor` will decide.\n",
       "  import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
       "    used when initializing from protocol buffer.\n",
       "  constraint: An optional projection function to be applied to the variable\n",
       "    after being updated by an `Optimizer` (e.g. used to implement norm\n",
       "    constraints or value constraints for layer weights). The function must\n",
       "    take as input the unprojected Tensor representing the value of the\n",
       "    variable and return the Tensor for the projected value (which must have\n",
       "    the same shape). Constraints are not safe to use when doing asynchronous\n",
       "    distributed training.\n",
       "  synchronization: Indicates when a distributed a variable will be\n",
       "    aggregated. Accepted values are constants defined in the class\n",
       "    `tf.VariableSynchronization`. By default the synchronization is set to\n",
       "    `AUTO` and the current `DistributionStrategy` chooses when to\n",
       "    synchronize.\n",
       "  aggregation: Indicates how a distributed variable will be aggregated.\n",
       "    Accepted values are constants defined in the class\n",
       "    `tf.VariableAggregation`.\n",
       "  shape: (optional) The shape of this variable. If None, the shape of\n",
       "    `initial_value` will be used. When setting this argument to\n",
       "    `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
       "    can be assigned with values of different shapes.\n",
       "  experimental_enable_variable_lifting: Whether to lift the variable out if\n",
       "    it's in a `tf.function`. Default is `True`. When this argument\n",
       "    is `True`, variable creation will follow the behavior and\n",
       "    restrictions described\n",
       "    [here](https://www.tensorflow.org/guide/function#creating_tfvariables).\n",
       "    If this argument is `False`, that description doesn't apply,\n",
       "    and you can freely create and use the variable in the\n",
       "    `tf.function`, as if it's a \"mutable `tf.Tensor`\". You can't\n",
       "    return the variable though.\n",
       "\n",
       "Raises:\n",
       "  ValueError: If both `variable_def` and initial_value are specified.\n",
       "  ValueError: If the initial value is not specified, or does not have a\n",
       "    shape and `validate_shape` is `True`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\n",
       "\u001b[0;31mType:\u001b[0m           VariableMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     BaseResourceVariable, VariableV1, DistributedVariable, TPUReplicatedVariable, AutoCastVariable, AutoCastVariable"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.Variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698cb5a-42fe-400c-a179-9214a8d59d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
